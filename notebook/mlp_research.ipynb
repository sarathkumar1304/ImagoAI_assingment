{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sarath_kumar/ImagoAI/notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sarath_kumar/ImagoAI'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# os.chdir(\"../\")\n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/TASK-ML-INTERN.csv\")\n",
    "\n",
    "# Log-transform the target variable to reduce skewness\n",
    "df[\"vomitoxin_ppb\"] = np.log1p(df[\"vomitoxin_ppb\"])\n",
    "\n",
    "# Identify and remove outliers using IQR\n",
    "Q1 = df[\"vomitoxin_ppb\"].quantile(0.25)\n",
    "Q3 = df[\"vomitoxin_ppb\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df = df[(df[\"vomitoxin_ppb\"] >= lower_bound) & (df[\"vomitoxin_ppb\"] <= upper_bound)]\n",
    "\n",
    "# Normalize spectral features using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = df.iloc[:, 1:-1].values  # Selecting spectral reflectance features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = df[\"vomitoxin_ppb\"].values  # Transformed target\n",
    "\n",
    "# Apply PCA to retain more variance\n",
    "pca = PCA(n_components=150)  # Increase components to 100\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define Optuna objective function for hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-03-15 11:30:42.410053: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 39.5683 - mae: 6.1029 - val_loss: 21.5681 - val_mae: 4.2438\n",
      "Epoch 2/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 17.9464 - mae: 3.6865 - val_loss: 16.0637 - val_mae: 2.9674\n",
      "Epoch 3/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.8311 - mae: 2.4752 - val_loss: 9.1340 - val_mae: 2.5949\n",
      "Epoch 4/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.5634 - mae: 2.3814 - val_loss: 6.6096 - val_mae: 2.1716\n",
      "Epoch 5/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.6278 - mae: 1.8465 - val_loss: 4.9944 - val_mae: 1.8551\n",
      "Epoch 6/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5662 - mae: 1.5367 - val_loss: 3.7471 - val_mae: 1.6216\n",
      "Epoch 7/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.2084 - mae: 1.1777 - val_loss: 2.9447 - val_mae: 1.3579\n",
      "Epoch 8/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6775 - mae: 1.0025 - val_loss: 2.4466 - val_mae: 1.2747\n",
      "Epoch 9/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4232 - mae: 0.9479 - val_loss: 2.3110 - val_mae: 1.1507\n",
      "Epoch 10/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1408 - mae: 0.8362 - val_loss: 2.1373 - val_mae: 1.1611\n",
      "Epoch 11/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9725 - mae: 0.7978 - val_loss: 2.1778 - val_mae: 1.1017\n",
      "Epoch 12/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8342 - mae: 0.7060 - val_loss: 2.1107 - val_mae: 1.1350\n",
      "Epoch 13/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8929 - mae: 0.7634 - val_loss: 2.2377 - val_mae: 1.0963\n",
      "Epoch 14/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7775 - mae: 0.7068 - val_loss: 2.0809 - val_mae: 1.0705\n",
      "Epoch 15/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7006 - mae: 0.6744 - val_loss: 2.1137 - val_mae: 1.0945\n",
      "Epoch 16/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6384 - mae: 0.6400 - val_loss: 2.1821 - val_mae: 1.0838\n",
      "Epoch 17/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6791 - mae: 0.6452 - val_loss: 2.1655 - val_mae: 1.1063\n",
      "Epoch 18/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5410 - mae: 0.5662 - val_loss: 2.2053 - val_mae: 1.1563\n",
      "Epoch 19/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5263 - mae: 0.5730 - val_loss: 2.2844 - val_mae: 1.1101\n",
      "Epoch 20/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5060 - mae: 0.5426 - val_loss: 2.2382 - val_mae: 1.1057\n",
      "Epoch 21/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4718 - mae: 0.5219 - val_loss: 2.2170 - val_mae: 1.1478\n",
      "Epoch 22/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4189 - mae: 0.5110 - val_loss: 2.3272 - val_mae: 1.1384\n",
      "Epoch 23/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3594 - mae: 0.4761 - val_loss: 2.3338 - val_mae: 1.1388\n",
      "Epoch 24/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3613 - mae: 0.4649 - val_loss: 2.3493 - val_mae: 1.1535\n",
      "Epoch 25/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.3059 - mae: 0.4372 - val_loss: 2.3434 - val_mae: 1.1442\n",
      "Epoch 26/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2895 - mae: 0.4207 - val_loss: 2.3161 - val_mae: 1.1518\n",
      "Epoch 27/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2587 - mae: 0.3904 - val_loss: 2.3446 - val_mae: 1.1316\n",
      "Epoch 28/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2343 - mae: 0.3807 - val_loss: 2.3441 - val_mae: 1.1568\n",
      "Epoch 29/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2444 - mae: 0.3987 - val_loss: 2.3836 - val_mae: 1.1495\n",
      "Epoch 30/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1844 - mae: 0.3461 - val_loss: 2.3906 - val_mae: 1.1511\n",
      "Epoch 31/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1564 - mae: 0.3130 - val_loss: 2.4288 - val_mae: 1.1592\n",
      "Epoch 32/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1530 - mae: 0.3163 - val_loss: 2.4002 - val_mae: 1.1600\n",
      "Epoch 33/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1419 - mae: 0.2968 - val_loss: 2.4588 - val_mae: 1.1786\n",
      "Epoch 34/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1244 - mae: 0.2757 - val_loss: 2.4574 - val_mae: 1.1815\n",
      "Epoch 35/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1290 - mae: 0.2896 - val_loss: 2.5065 - val_mae: 1.1861\n",
      "Epoch 36/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0897 - mae: 0.2394 - val_loss: 2.5334 - val_mae: 1.1838\n",
      "Epoch 37/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0805 - mae: 0.2240 - val_loss: 2.5067 - val_mae: 1.1737\n",
      "Epoch 38/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0617 - mae: 0.1963 - val_loss: 2.4659 - val_mae: 1.1737\n",
      "Epoch 39/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0581 - mae: 0.1898 - val_loss: 2.4727 - val_mae: 1.1666\n",
      "Epoch 40/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0657 - mae: 0.2007 - val_loss: 2.5059 - val_mae: 1.1707\n",
      "Epoch 41/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0407 - mae: 0.1590 - val_loss: 2.5181 - val_mae: 1.1749\n",
      "Epoch 42/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0424 - mae: 0.1537 - val_loss: 2.4818 - val_mae: 1.1655\n",
      "Epoch 43/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0281 - mae: 0.1333 - val_loss: 2.4799 - val_mae: 1.1635\n",
      "Epoch 44/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0222 - mae: 0.1162 - val_loss: 2.4947 - val_mae: 1.1642\n",
      "Epoch 45/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0209 - mae: 0.1079 - val_loss: 2.5108 - val_mae: 1.1664\n",
      "Epoch 46/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0186 - mae: 0.1032 - val_loss: 2.5246 - val_mae: 1.1709\n",
      "Epoch 47/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0158 - mae: 0.0945 - val_loss: 2.5090 - val_mae: 1.1691\n",
      "Epoch 48/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0127 - mae: 0.0883 - val_loss: 2.5192 - val_mae: 1.1672\n",
      "Epoch 49/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0153 - mae: 0.0935 - val_loss: 2.5091 - val_mae: 1.1694\n",
      "Epoch 50/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0096 - mae: 0.0708 - val_loss: 2.5230 - val_mae: 1.1690\n",
      "Epoch 51/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0069 - mae: 0.0634 - val_loss: 2.5127 - val_mae: 1.1666\n",
      "Epoch 52/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0068 - mae: 0.0622 - val_loss: 2.5252 - val_mae: 1.1705\n",
      "Epoch 53/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0074 - mae: 0.0606 - val_loss: 2.5262 - val_mae: 1.1694\n",
      "Epoch 54/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0050 - mae: 0.0536 - val_loss: 2.5157 - val_mae: 1.1651\n",
      "Epoch 55/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - mae: 0.0457 - val_loss: 2.5027 - val_mae: 1.1619\n",
      "Epoch 56/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0033 - mae: 0.0444 - val_loss: 2.5040 - val_mae: 1.1636\n",
      "Epoch 57/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0031 - mae: 0.0430 - val_loss: 2.5036 - val_mae: 1.1624\n",
      "Epoch 58/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0030 - mae: 0.0419 - val_loss: 2.5059 - val_mae: 1.1631\n",
      "Epoch 59/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0019 - mae: 0.0324 - val_loss: 2.5063 - val_mae: 1.1613\n",
      "Epoch 60/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0020 - mae: 0.0340 - val_loss: 2.5201 - val_mae: 1.1635\n",
      "Epoch 61/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0025 - mae: 0.0396 - val_loss: 2.5163 - val_mae: 1.1625\n",
      "Epoch 62/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 2.5008 - val_mae: 1.1596\n",
      "Epoch 63/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.5975e-04 - mae: 0.0239 - val_loss: 2.5032 - val_mae: 1.1597\n",
      "Epoch 64/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.3952e-04 - mae: 0.0203 - val_loss: 2.5075 - val_mae: 1.1604\n",
      "Epoch 65/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.3032e-04 - mae: 0.0182 - val_loss: 2.5079 - val_mae: 1.1603\n",
      "Epoch 66/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.0795e-04 - mae: 0.0171 - val_loss: 2.5055 - val_mae: 1.1607\n",
      "Epoch 67/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.2584e-04 - mae: 0.0166 - val_loss: 2.5076 - val_mae: 1.1610\n",
      "Epoch 68/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.4927e-04 - mae: 0.0173 - val_loss: 2.5111 - val_mae: 1.1613\n",
      "Epoch 69/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.1454e-04 - mae: 0.0133 - val_loss: 2.5110 - val_mae: 1.1617\n",
      "Epoch 70/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.7007e-04 - mae: 0.0117 - val_loss: 2.5087 - val_mae: 1.1605\n",
      "Epoch 71/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.7094e-04 - mae: 0.0107 - val_loss: 2.5099 - val_mae: 1.1603\n",
      "Epoch 72/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2731e-04 - mae: 0.0109 - val_loss: 2.5085 - val_mae: 1.1603\n",
      "Epoch 73/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6022e-04 - mae: 0.0087 - val_loss: 2.5119 - val_mae: 1.1611\n",
      "Epoch 74/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0747e-04 - mae: 0.0074 - val_loss: 2.5130 - val_mae: 1.1603\n",
      "Epoch 75/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0374e-04 - mae: 0.0069 - val_loss: 2.5124 - val_mae: 1.1604\n",
      "Epoch 76/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4027e-04 - mae: 0.0076 - val_loss: 2.5142 - val_mae: 1.1604\n",
      "Epoch 77/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.3198e-05 - mae: 0.0068 - val_loss: 2.5132 - val_mae: 1.1612\n",
      "Epoch 78/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3403e-04 - mae: 0.0089 - val_loss: 2.5144 - val_mae: 1.1614\n",
      "Epoch 79/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0946e-04 - mae: 0.0080 - val_loss: 2.5142 - val_mae: 1.1619\n",
      "Epoch 80/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.8632e-05 - mae: 0.0059 - val_loss: 2.5167 - val_mae: 1.1615\n",
      "Epoch 81/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.9502e-05 - mae: 0.0060 - val_loss: 2.5155 - val_mae: 1.1620\n",
      "Epoch 82/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.4969e-05 - mae: 0.0045 - val_loss: 2.5149 - val_mae: 1.1615\n",
      "Epoch 83/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.0195e-05 - mae: 0.0049 - val_loss: 2.5139 - val_mae: 1.1613\n",
      "Epoch 84/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.1449e-05 - mae: 0.0041 - val_loss: 2.5156 - val_mae: 1.1614\n",
      "Epoch 85/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.3436e-05 - mae: 0.0033 - val_loss: 2.5148 - val_mae: 1.1615\n",
      "Epoch 86/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8778e-05 - mae: 0.0033 - val_loss: 2.5145 - val_mae: 1.1613\n",
      "Epoch 87/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7199e-05 - mae: 0.0026 - val_loss: 2.5153 - val_mae: 1.1614\n",
      "Epoch 88/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.3369e-06 - mae: 0.0021 - val_loss: 2.5153 - val_mae: 1.1610\n",
      "Epoch 89/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2434e-05 - mae: 0.0022 - val_loss: 2.5155 - val_mae: 1.1612\n",
      "Epoch 90/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.3278e-06 - mae: 0.0017 - val_loss: 2.5147 - val_mae: 1.1613\n",
      "Epoch 91/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.5816e-06 - mae: 0.0017 - val_loss: 2.5155 - val_mae: 1.1614\n",
      "Epoch 92/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.9569e-06 - mae: 0.0012 - val_loss: 2.5159 - val_mae: 1.1614\n",
      "Epoch 93/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.5683e-06 - mae: 0.0015 - val_loss: 2.5160 - val_mae: 1.1615\n",
      "Epoch 94/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.4491e-06 - mae: 0.0012 - val_loss: 2.5159 - val_mae: 1.1615\n",
      "Epoch 95/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3677e-06 - mae: 0.0011 - val_loss: 2.5159 - val_mae: 1.1616\n",
      "Epoch 96/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0091e-06 - mae: 0.0010 - val_loss: 2.5162 - val_mae: 1.1615\n",
      "Epoch 97/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5059e-06 - mae: 8.0271e-04 - val_loss: 2.5160 - val_mae: 1.1616\n",
      "Epoch 98/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2606e-06 - mae: 7.0364e-04 - val_loss: 2.5163 - val_mae: 1.1616\n",
      "Epoch 99/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0764e-06 - mae: 0.0010 - val_loss: 2.5163 - val_mae: 1.1616\n",
      "Epoch 100/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.7124e-06 - mae: 0.0012 - val_loss: 2.5159 - val_mae: 1.1615\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4375 - mae: 1.1495\n",
      "Test MAE: 1.1614773273468018\n"
     ]
    }
   ],
   "source": [
    "def build_mlp():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)  # Output layer for regression\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Train the MLP model\n",
    "mlp_model = build_mlp()\n",
    "mlp_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# Evaluate the MLP model\n",
    "test_loss, test_mae = mlp_model.evaluate(X_test, y_test)\n",
    "print(f\"Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 9.3734 - mae: 5.6301 - val_loss: 7.8450 - val_mae: 4.6806\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.2357 - mae: 4.2222 - val_loss: 5.5136 - val_mae: 2.9310\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.6971 - mae: 3.2551 - val_loss: 4.8060 - val_mae: 2.7202\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.0774 - mae: 3.1188 - val_loss: 4.2558 - val_mae: 2.5643\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.2109 - mae: 2.6126 - val_loss: 3.6499 - val_mae: 2.2581\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.8493 - mae: 2.5224 - val_loss: 3.1517 - val_mae: 1.9794\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.2108 - mae: 2.0749 - val_loss: 2.7696 - val_mae: 1.7649\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9040 - mae: 1.9384 - val_loss: 2.6026 - val_mae: 1.6958\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.8051 - mae: 1.9724 - val_loss: 2.4123 - val_mae: 1.6380\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.4714 - mae: 1.7458 - val_loss: 2.3007 - val_mae: 1.6398\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.3176 - mae: 1.6829 - val_loss: 2.2075 - val_mae: 1.6309\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.2123 - mae: 1.6544 - val_loss: 2.1293 - val_mae: 1.6195\n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.0884 - mae: 1.5968 - val_loss: 2.0697 - val_mae: 1.6214\n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.1601 - mae: 1.7430 - val_loss: 2.0551 - val_mae: 1.6711\n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.0841 - mae: 1.7052 - val_loss: 1.9768 - val_mae: 1.6260\n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8979 - mae: 1.5523 - val_loss: 1.9222 - val_mae: 1.6036\n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8748 - mae: 1.5718 - val_loss: 1.9062 - val_mae: 1.6344\n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0151 - mae: 1.7503 - val_loss: 1.8784 - val_mae: 1.6420\n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.8237 - mae: 1.5762 - val_loss: 1.8480 - val_mae: 1.6443\n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7778 - mae: 1.5516 - val_loss: 1.9166 - val_mae: 1.7280\n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8014 - mae: 1.6107 - val_loss: 1.8473 - val_mae: 1.6768\n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7241 - mae: 1.5503 - val_loss: 1.7766 - val_mae: 1.6213\n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7715 - mae: 1.6268 - val_loss: 1.7612 - val_mae: 1.6356\n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6750 - mae: 1.5368 - val_loss: 1.7476 - val_mae: 1.6376\n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5539 - mae: 1.4284 - val_loss: 1.7684 - val_mae: 1.6547\n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6088 - mae: 1.5050 - val_loss: 1.7720 - val_mae: 1.6829\n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.6020 - mae: 1.5082 - val_loss: 1.7130 - val_mae: 1.6406\n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6502 - mae: 1.5696 - val_loss: 1.7329 - val_mae: 1.6420\n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6675 - mae: 1.6124 - val_loss: 1.7134 - val_mae: 1.6508\n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5874 - mae: 1.5098 - val_loss: 1.6764 - val_mae: 1.6262\n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5748 - mae: 1.5228 - val_loss: 1.7126 - val_mae: 1.6749\n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4737 - mae: 1.4330 - val_loss: 1.8374 - val_mae: 1.8222\n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5630 - mae: 1.5495 - val_loss: 1.7074 - val_mae: 1.6906\n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5307 - mae: 1.5106 - val_loss: 1.7696 - val_mae: 1.7650\n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5507 - mae: 1.5387 - val_loss: 1.6955 - val_mae: 1.6815\n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4274 - mae: 1.4270 - val_loss: 1.6650 - val_mae: 1.6656\n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4922 - mae: 1.4916 - val_loss: 1.6814 - val_mae: 1.6837\n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4975 - mae: 1.4916 - val_loss: 1.6770 - val_mae: 1.6712\n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4367 - mae: 1.4267 - val_loss: 1.6735 - val_mae: 1.6903\n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4653 - mae: 1.4746 - val_loss: 1.6372 - val_mae: 1.6614\n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4126 - mae: 1.4185 - val_loss: 1.6457 - val_mae: 1.6752\n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4339 - mae: 1.4466 - val_loss: 1.6854 - val_mae: 1.7057\n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3990 - mae: 1.4071 - val_loss: 1.6625 - val_mae: 1.6962\n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4924 - mae: 1.5318 - val_loss: 1.6984 - val_mae: 1.7277\n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4624 - mae: 1.4937 - val_loss: 1.6479 - val_mae: 1.6818\n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3284 - mae: 1.3543 - val_loss: 1.7242 - val_mae: 1.7606\n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4067 - mae: 1.4379 - val_loss: 1.7507 - val_mae: 1.7834\n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4147 - mae: 1.4466 - val_loss: 1.6996 - val_mae: 1.7500\n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4459 - mae: 1.4875 - val_loss: 1.7130 - val_mae: 1.7502\n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3639 - mae: 1.3910 - val_loss: 1.6435 - val_mae: 1.7020\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7437 - mae: 1.7751\n",
      "Test MAE: 1.6613751649856567\n",
      "Test R² Score: 0.1457977142744621\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, regularizers\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/TASK-ML-INTERN.csv\")\n",
    "\n",
    "# Log-transform the target variable to reduce skewness\n",
    "df[\"vomitoxin_ppb\"] = np.log1p(df[\"vomitoxin_ppb\"])\n",
    "\n",
    "# Identify and handle outliers using Winsorization\n",
    "Q1 = df[\"vomitoxin_ppb\"].quantile(0.25)\n",
    "Q3 = df[\"vomitoxin_ppb\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df[\"vomitoxin_ppb\"] = np.clip(df[\"vomitoxin_ppb\"], lower_bound, upper_bound)\n",
    "\n",
    "# Normalize spectral features using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = df.iloc[:, 1:-1].values  # Selecting spectral reflectance features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = df[\"vomitoxin_ppb\"].values  # Transformed target\n",
    "\n",
    "# Apply PCA to retain optimal variance (Reduced to 100 components)\n",
    "pca = PCA(n_components=100)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define and train an optimized Multi-Layer Perceptron (MLP) model\n",
    "def build_mlp():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train.shape[1],)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "        layers.Dense(1)  # Output layer for regression\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.Huber(), metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Train the optimized MLP model\n",
    "mlp_model = build_mlp()\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "mlp_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Evaluate the optimized MLP model\n",
    "y_test_pred = mlp_model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "test_loss, test_mae = mlp_model.evaluate(X_test, y_test)\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "print(f\"Test R² Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:39:34,831] A new study created in memory with name: no-name-9adaa9c5-0df6-46da-8915-a0b74fab8403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:39:42,156] Trial 0 finished with value: 0.1805069062186041 and parameters: {'units_l1': 450, 'dropout_l1': 0.14175530034082626, 'units_l2': 146, 'dropout_l2': 0.3120105898920607, 'units_l3': 75, 'lr': 0.004808534492062374, 'epochs': 97, 'batch_size': 16}. Best is trial 0 with value: 0.1805069062186041.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:39:52,730] Trial 1 finished with value: 0.14407055991859818 and parameters: {'units_l1': 144, 'dropout_l1': 0.23780955907888127, 'units_l2': 252, 'dropout_l2': 0.2612161336175099, 'units_l3': 52, 'lr': 0.0010671052962448794, 'epochs': 133, 'batch_size': 64}. Best is trial 0 with value: 0.1805069062186041.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:40:05,828] Trial 2 finished with value: 0.14091574978208476 and parameters: {'units_l1': 397, 'dropout_l1': 0.4781832620923768, 'units_l2': 256, 'dropout_l2': 0.22955662180430447, 'units_l3': 62, 'lr': 0.0009258187999898206, 'epochs': 97, 'batch_size': 64}. Best is trial 0 with value: 0.1805069062186041.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:40:20,627] Trial 3 finished with value: 0.1507176298611882 and parameters: {'units_l1': 214, 'dropout_l1': 0.4152492752460354, 'units_l2': 195, 'dropout_l2': 0.4688789208800246, 'units_l3': 80, 'lr': 0.0006052501652419836, 'epochs': 81, 'batch_size': 16}. Best is trial 0 with value: 0.1805069062186041.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:40:28,162] Trial 4 finished with value: 0.16219495581699994 and parameters: {'units_l1': 232, 'dropout_l1': 0.2923864453879724, 'units_l2': 120, 'dropout_l2': 0.20053991338457947, 'units_l3': 112, 'lr': 0.001925294132305607, 'epochs': 100, 'batch_size': 16}. Best is trial 0 with value: 0.1805069062186041.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:40:34,224] Trial 5 finished with value: 0.18547681757842516 and parameters: {'units_l1': 276, 'dropout_l1': 0.3426768072453379, 'units_l2': 88, 'dropout_l2': 0.26115229593982603, 'units_l3': 91, 'lr': 0.008115598961916274, 'epochs': 54, 'batch_size': 64}. Best is trial 5 with value: 0.18547681757842516.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:40:40,000] Trial 6 finished with value: 0.11504642792972952 and parameters: {'units_l1': 171, 'dropout_l1': 0.15522215822203128, 'units_l2': 223, 'dropout_l2': 0.174147299362178, 'units_l3': 90, 'lr': 0.00324167768636344, 'epochs': 100, 'batch_size': 64}. Best is trial 5 with value: 0.18547681757842516.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:40:48,303] Trial 7 finished with value: 0.14128615435266934 and parameters: {'units_l1': 292, 'dropout_l1': 0.23891033489635274, 'units_l2': 169, 'dropout_l2': 0.11828201230805241, 'units_l3': 115, 'lr': 0.0020445016093271406, 'epochs': 82, 'batch_size': 32}. Best is trial 5 with value: 0.18547681757842516.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:40:58,001] Trial 8 finished with value: 0.16453063283189462 and parameters: {'units_l1': 166, 'dropout_l1': 0.4768510576757501, 'units_l2': 129, 'dropout_l2': 0.20941383092687654, 'units_l3': 82, 'lr': 0.0016837304628851085, 'epochs': 131, 'batch_size': 64}. Best is trial 5 with value: 0.18547681757842516.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:41:08,956] Trial 9 finished with value: 0.09348534664115449 and parameters: {'units_l1': 426, 'dropout_l1': 0.28524409817899665, 'units_l2': 193, 'dropout_l2': 0.32899757508874383, 'units_l3': 113, 'lr': 0.0008692393790690594, 'epochs': 146, 'batch_size': 64}. Best is trial 5 with value: 0.18547681757842516.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:41:19,542] Trial 10 finished with value: 0.23417696469395666 and parameters: {'units_l1': 340, 'dropout_l1': 0.37046719686626706, 'units_l2': 70, 'dropout_l2': 0.39890413600561947, 'units_l3': 32, 'lr': 0.008921769793593336, 'epochs': 57, 'batch_size': 32}. Best is trial 10 with value: 0.23417696469395666.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:41:27,264] Trial 11 finished with value: 0.18497507831010074 and parameters: {'units_l1': 338, 'dropout_l1': 0.38388037085869087, 'units_l2': 64, 'dropout_l2': 0.4233084636171962, 'units_l3': 41, 'lr': 0.009782510183442089, 'epochs': 50, 'batch_size': 32}. Best is trial 10 with value: 0.23417696469395666.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:41:35,948] Trial 12 finished with value: 0.2171870393770845 and parameters: {'units_l1': 509, 'dropout_l1': 0.36390387406937974, 'units_l2': 66, 'dropout_l2': 0.38757483663355946, 'units_l3': 97, 'lr': 0.008119201089671641, 'epochs': 52, 'batch_size': 32}. Best is trial 10 with value: 0.23417696469395666.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:41:43,208] Trial 13 finished with value: 0.11748061015492584 and parameters: {'units_l1': 493, 'dropout_l1': 0.4003973322101148, 'units_l2': 87, 'dropout_l2': 0.3792674735603035, 'units_l3': 36, 'lr': 0.005756578262067984, 'epochs': 66, 'batch_size': 32}. Best is trial 10 with value: 0.23417696469395666.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:41:51,144] Trial 14 finished with value: 0.17946617576439816 and parameters: {'units_l1': 366, 'dropout_l1': 0.3475193721420166, 'units_l2': 66, 'dropout_l2': 0.3808077114325869, 'units_l3': 100, 'lr': 0.0047682426809714335, 'epochs': 67, 'batch_size': 32}. Best is trial 10 with value: 0.23417696469395666.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:41:59,826] Trial 15 finished with value: 0.231314272448781 and parameters: {'units_l1': 496, 'dropout_l1': 0.4413139170273366, 'units_l2': 104, 'dropout_l2': 0.48370594709214865, 'units_l3': 61, 'lr': 0.006998774993914769, 'epochs': 67, 'batch_size': 32}. Best is trial 10 with value: 0.23417696469395666.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:42:10,192] Trial 16 finished with value: 0.21495826450307276 and parameters: {'units_l1': 472, 'dropout_l1': 0.4411040496587755, 'units_l2': 104, 'dropout_l2': 0.4875195446200807, 'units_l3': 62, 'lr': 0.006210033029215632, 'epochs': 70, 'batch_size': 32}. Best is trial 10 with value: 0.23417696469395666.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:42:17,032] Trial 17 finished with value: 0.20933383441510445 and parameters: {'units_l1': 391, 'dropout_l1': 0.44469653972020745, 'units_l2': 103, 'dropout_l2': 0.43828360289976787, 'units_l3': 49, 'lr': 0.003289222127772314, 'epochs': 80, 'batch_size': 32}. Best is trial 10 with value: 0.23417696469395666.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:42:25,292] Trial 18 finished with value: 0.17451398260049544 and parameters: {'units_l1': 309, 'dropout_l1': 0.32932490690369787, 'units_l2': 149, 'dropout_l2': 0.4928608375100479, 'units_l3': 33, 'lr': 0.0029271347643774416, 'epochs': 119, 'batch_size': 32}. Best is trial 10 with value: 0.23417696469395666.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:42:33,047] Trial 19 finished with value: 0.206728916096255 and parameters: {'units_l1': 434, 'dropout_l1': 0.4876251035516389, 'units_l2': 90, 'dropout_l2': 0.4286034984361798, 'units_l3': 67, 'lr': 0.003971823070207044, 'epochs': 64, 'batch_size': 32}. Best is trial 10 with value: 0.23417696469395666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 6.0975 - mae: 4.3896 - val_loss: 2.9034 - val_mae: 2.5912\n",
      "Epoch 2/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.9022 - mae: 2.6215 - val_loss: 1.9864 - val_mae: 1.8047\n",
      "Epoch 3/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1292 - mae: 2.0057 - val_loss: 1.7263 - val_mae: 1.6822\n",
      "Epoch 4/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0003 - mae: 2.0077 - val_loss: 1.7658 - val_mae: 1.8540\n",
      "Epoch 5/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8304 - mae: 1.9134 - val_loss: 1.6587 - val_mae: 1.7932\n",
      "Epoch 6/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6422 - mae: 1.7619 - val_loss: 1.4795 - val_mae: 1.6029\n",
      "Epoch 7/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.7642 - mae: 1.9375 - val_loss: 1.5397 - val_mae: 1.7312\n",
      "Epoch 8/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7991 - mae: 1.9983 - val_loss: 1.4571 - val_mae: 1.6239\n",
      "Epoch 9/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6311 - mae: 1.8342 - val_loss: 1.4005 - val_mae: 1.5895\n",
      "Epoch 10/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5774 - mae: 1.7934 - val_loss: 1.3316 - val_mae: 1.5294\n",
      "Epoch 11/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6428 - mae: 1.8682 - val_loss: 1.4105 - val_mae: 1.6500\n",
      "Epoch 12/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.6493 - mae: 1.8885 - val_loss: 1.4341 - val_mae: 1.6764\n",
      "Epoch 13/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6610 - mae: 1.9067 - val_loss: 1.6322 - val_mae: 1.9082\n",
      "Epoch 14/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7104 - mae: 1.9775 - val_loss: 1.3711 - val_mae: 1.6071\n",
      "Epoch 15/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5112 - mae: 1.7596 - val_loss: 1.4396 - val_mae: 1.6427\n",
      "Epoch 16/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7189 - mae: 1.9684 - val_loss: 1.2980 - val_mae: 1.5283\n",
      "Epoch 17/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5508 - mae: 1.8024 - val_loss: 1.3247 - val_mae: 1.5953\n",
      "Epoch 18/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3704 - mae: 1.6285 - val_loss: 1.3304 - val_mae: 1.5887\n",
      "Epoch 19/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3843 - mae: 1.6439 - val_loss: 1.2772 - val_mae: 1.5465\n",
      "Epoch 20/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4269 - mae: 1.6937 - val_loss: 1.3277 - val_mae: 1.5853\n",
      "Epoch 21/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3594 - mae: 1.5956 - val_loss: 1.3039 - val_mae: 1.5751\n",
      "Epoch 22/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4066 - mae: 1.6585 - val_loss: 1.2693 - val_mae: 1.5285\n",
      "Epoch 23/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3561 - mae: 1.6110 - val_loss: 1.2748 - val_mae: 1.5251\n",
      "Epoch 24/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4532 - mae: 1.6975 - val_loss: 1.2976 - val_mae: 1.5055\n",
      "Epoch 25/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4196 - mae: 1.6398 - val_loss: 1.2896 - val_mae: 1.5202\n",
      "Epoch 26/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3626 - mae: 1.5972 - val_loss: 1.2883 - val_mae: 1.5343\n",
      "Epoch 27/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4771 - mae: 1.7276 - val_loss: 1.3853 - val_mae: 1.6534\n",
      "Epoch 28/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4026 - mae: 1.6608 - val_loss: 1.2474 - val_mae: 1.5088\n",
      "Epoch 29/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3646 - mae: 1.6210 - val_loss: 1.2452 - val_mae: 1.4906\n",
      "Epoch 30/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3245 - mae: 1.5751 - val_loss: 1.2426 - val_mae: 1.4937\n",
      "Epoch 31/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4221 - mae: 1.6754 - val_loss: 1.2586 - val_mae: 1.5123\n",
      "Epoch 32/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.3827 - mae: 1.6309 - val_loss: 1.2836 - val_mae: 1.5392\n",
      "Epoch 33/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3940 - mae: 1.6453 - val_loss: 1.2377 - val_mae: 1.4771\n",
      "Epoch 34/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2692 - mae: 1.5125 - val_loss: 1.2607 - val_mae: 1.5184\n",
      "Epoch 35/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4051 - mae: 1.6613 - val_loss: 1.2232 - val_mae: 1.4599\n",
      "Epoch 36/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3544 - mae: 1.5957 - val_loss: 1.3608 - val_mae: 1.6108\n",
      "Epoch 37/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4353 - mae: 1.6803 - val_loss: 1.2062 - val_mae: 1.4476\n",
      "Epoch 38/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2975 - mae: 1.5522 - val_loss: 1.2781 - val_mae: 1.5565\n",
      "Epoch 39/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3620 - mae: 1.6323 - val_loss: 1.2340 - val_mae: 1.5082\n",
      "Epoch 40/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3072 - mae: 1.5726 - val_loss: 1.2167 - val_mae: 1.4829\n",
      "Epoch 41/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3300 - mae: 1.6020 - val_loss: 1.2430 - val_mae: 1.5220\n",
      "Epoch 42/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3321 - mae: 1.5992 - val_loss: 1.2199 - val_mae: 1.4838\n",
      "Epoch 43/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3937 - mae: 1.6647 - val_loss: 1.2492 - val_mae: 1.5209\n",
      "Epoch 44/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2425 - mae: 1.5073 - val_loss: 1.1943 - val_mae: 1.4375\n",
      "Epoch 45/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2708 - mae: 1.5270 - val_loss: 1.2178 - val_mae: 1.4799\n",
      "Epoch 46/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3210 - mae: 1.5678 - val_loss: 1.2649 - val_mae: 1.5372\n",
      "Epoch 47/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1961 - mae: 1.4558 - val_loss: 1.2207 - val_mae: 1.4770\n",
      "Epoch 48/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2560 - mae: 1.4964 - val_loss: 1.2790 - val_mae: 1.5472\n",
      "Epoch 49/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2878 - mae: 1.5672 - val_loss: 1.2257 - val_mae: 1.4980\n",
      "Epoch 50/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2956 - mae: 1.5646 - val_loss: 1.2164 - val_mae: 1.4824\n",
      "Epoch 51/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3103 - mae: 1.5733 - val_loss: 1.2004 - val_mae: 1.4387\n",
      "Epoch 52/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3713 - mae: 1.6180 - val_loss: 1.2281 - val_mae: 1.4839\n",
      "Epoch 53/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3669 - mae: 1.6249 - val_loss: 1.2442 - val_mae: 1.5071\n",
      "Epoch 54/57\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2803 - mae: 1.5341 - val_loss: 1.2242 - val_mae: 1.4840\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3412 - mae: 1.5974\n",
      "Test MAE: 1.437475562095642\n",
      "Test R² Score: 0.1854515272800985\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define Optuna objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(trial.suggest_int('units_l1', 128, 512), activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train.shape[1],)),\n",
    "        layers.Dropout(trial.suggest_float('dropout_l1', 0.1, 0.5)),\n",
    "        layers.Dense(trial.suggest_int('units_l2', 64, 256), activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "        layers.Dropout(trial.suggest_float('dropout_l2', 0.1, 0.5)),\n",
    "        layers.Dense(trial.suggest_int('units_l3', 32, 128), activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=trial.suggest_float('lr', 5e-4, 1e-2, log=True))\n",
    "    model.compile(optimizer=optimizer, loss=keras.losses.Huber(), metrics=['mae'])\n",
    "    \n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=trial.suggest_int('epochs', 50, 150), batch_size=trial.suggest_categorical('batch_size', [16, 32, 64]), callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Train final model with best hyperparameters\n",
    "best_params = study.best_params\n",
    "final_model = keras.Sequential([\n",
    "    layers.Dense(best_params['units_l1'], activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(best_params['dropout_l1']),\n",
    "    layers.Dense(best_params['units_l2'], activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(best_params['dropout_l2']),\n",
    "    layers.Dense(best_params['units_l3'], activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "final_optimizer = keras.optimizers.Adam(learning_rate=best_params['lr'])\n",
    "final_model.compile(optimizer=final_optimizer, loss=keras.losses.Huber(), metrics=['mae'])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "final_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=best_params['epochs'], batch_size=best_params['batch_size'], callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Evaluate final model\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "test_loss, test_mae = final_model.evaluate(X_test, y_test)\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "print(f\"Test R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7437 - mae: 1.7751\n",
      "Test MAE: 1.6613751649856567\n",
      "Test R² Score: 0.1457977142744621\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = mlp_model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "test_loss, test_mae = mlp_model.evaluate(X_test, y_test)\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "print(f\"Test R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Performance Interpretation**\n",
    "\n",
    "#### **1. Optimized MLP Performance**\n",
    "- **Test MAE: 1.44** → The model's average prediction error is **1.44 ppb** in log-transformed DON concentration.\n",
    "- **R² Score: 0.185** → The model explains **18.5%** of the variance in DON concentration, which is still low.\n",
    "\n",
    "#### **2. Key Takeaways**\n",
    "- The **R² score improved slightly** compared to previous runs, but it's still relatively low.\n",
    "- **Possible reasons for limited performance:**\n",
    "  - **High variance in DON concentration**: Even after log transformation, extreme values may still impact predictions.\n",
    "  - **Spectral Data Complexity**: Some important spectral bands might have been lost in PCA.\n",
    "  - **Neural Network Limitations**: The model may struggle with **non-linear relationships** in the data.\n",
    "\n",
    "\n",
    "#### **4. Next Steps**\n",
    "- **Increase PCA components further** (e.g., **180-200**) to retain more variance.\n",
    "- **Try ensemble methods (XGBoost + MLP stacking)** for better performance.\n",
    "- **Experiment with different architectures (Residual Connections, Transformers)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:46:39,501] A new study created in memory with name: no-name-c59e5eaf-8efc-42db-b8da-1c3a1cdc09c0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Test MAE: 1.66173920226296\n",
      "XGBoost Test RMSE: 2.1803631071727163\n",
      "XGBoost Test R² Score: 0.23307900383496583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:46:50,177] Trial 0 finished with value: 0.18583118154963651 and parameters: {'units_l1': 355, 'dropout_l1': 0.1456545991389313, 'units_l2': 149, 'dropout_l2': 0.396992357513159, 'units_l3': 114, 'lr': 0.004182670406044688, 'epochs': 69, 'batch_size': 16}. Best is trial 0 with value: 0.18583118154963651.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:46:57,140] Trial 1 finished with value: 0.18171298293241278 and parameters: {'units_l1': 334, 'dropout_l1': 0.2831863693170332, 'units_l2': 102, 'dropout_l2': 0.1720008408253112, 'units_l3': 97, 'lr': 0.004214059896438681, 'epochs': 136, 'batch_size': 16}. Best is trial 0 with value: 0.18583118154963651.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:47:07,736] Trial 2 finished with value: 0.10461226490526798 and parameters: {'units_l1': 283, 'dropout_l1': 0.3427423995686232, 'units_l2': 203, 'dropout_l2': 0.33760690407733884, 'units_l3': 73, 'lr': 0.001178140732413033, 'epochs': 60, 'batch_size': 64}. Best is trial 0 with value: 0.18583118154963651.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:47:19,446] Trial 3 finished with value: 0.15624741277417775 and parameters: {'units_l1': 379, 'dropout_l1': 0.4298626842125821, 'units_l2': 229, 'dropout_l2': 0.11611445113587125, 'units_l3': 52, 'lr': 0.004400581112101011, 'epochs': 51, 'batch_size': 16}. Best is trial 0 with value: 0.18583118154963651.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:47:27,871] Trial 4 finished with value: 0.14533764824904005 and parameters: {'units_l1': 469, 'dropout_l1': 0.2944739679788998, 'units_l2': 163, 'dropout_l2': 0.23367454698967088, 'units_l3': 86, 'lr': 0.006178235289786946, 'epochs': 60, 'batch_size': 32}. Best is trial 0 with value: 0.18583118154963651.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:47:36,448] Trial 5 finished with value: 0.11239085271092464 and parameters: {'units_l1': 439, 'dropout_l1': 0.2279199887036817, 'units_l2': 117, 'dropout_l2': 0.11103538591805472, 'units_l3': 58, 'lr': 0.001408211243814871, 'epochs': 134, 'batch_size': 64}. Best is trial 0 with value: 0.18583118154963651.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:47:46,525] Trial 6 finished with value: 0.19009621548638367 and parameters: {'units_l1': 132, 'dropout_l1': 0.4853637727836224, 'units_l2': 119, 'dropout_l2': 0.4219147929258651, 'units_l3': 128, 'lr': 0.0062067656277849225, 'epochs': 139, 'batch_size': 64}. Best is trial 6 with value: 0.19009621548638367.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:47:59,562] Trial 7 finished with value: 0.1761954446483751 and parameters: {'units_l1': 340, 'dropout_l1': 0.4216272758635734, 'units_l2': 143, 'dropout_l2': 0.453593066425967, 'units_l3': 37, 'lr': 0.009642005427440965, 'epochs': 141, 'batch_size': 16}. Best is trial 6 with value: 0.19009621548638367.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:48:09,847] Trial 8 finished with value: 0.12358625861728656 and parameters: {'units_l1': 242, 'dropout_l1': 0.3272002395368505, 'units_l2': 239, 'dropout_l2': 0.316899141999444, 'units_l3': 61, 'lr': 0.002260074514549142, 'epochs': 122, 'batch_size': 64}. Best is trial 6 with value: 0.19009621548638367.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:48:18,938] Trial 9 finished with value: 0.1333893649503145 and parameters: {'units_l1': 348, 'dropout_l1': 0.30221467085217385, 'units_l2': 163, 'dropout_l2': 0.18117153556125287, 'units_l3': 108, 'lr': 0.0015773133647018645, 'epochs': 74, 'batch_size': 32}. Best is trial 6 with value: 0.19009621548638367.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:48:32,240] Trial 10 finished with value: 0.15089905225717637 and parameters: {'units_l1': 151, 'dropout_l1': 0.4870201241278988, 'units_l2': 75, 'dropout_l2': 0.49102111580364094, 'units_l3': 127, 'lr': 0.0005841337269523654, 'epochs': 104, 'batch_size': 64}. Best is trial 6 with value: 0.19009621548638367.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:48:38,552] Trial 11 finished with value: 0.14535940602421848 and parameters: {'units_l1': 133, 'dropout_l1': 0.12873306655349376, 'units_l2': 129, 'dropout_l2': 0.39138522119828517, 'units_l3': 125, 'lr': 0.003338365703061698, 'epochs': 90, 'batch_size': 16}. Best is trial 6 with value: 0.19009621548638367.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:48:44,319] Trial 12 finished with value: 0.15963880263239083 and parameters: {'units_l1': 248, 'dropout_l1': 0.11923198500972682, 'units_l2': 175, 'dropout_l2': 0.4073384275111999, 'units_l3': 110, 'lr': 0.00907731918319511, 'epochs': 110, 'batch_size': 64}. Best is trial 6 with value: 0.19009621548638367.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:48:52,384] Trial 13 finished with value: 0.22473221371986252 and parameters: {'units_l1': 195, 'dropout_l1': 0.20799628197665226, 'units_l2': 88, 'dropout_l2': 0.39635157545216404, 'units_l3': 114, 'lr': 0.005622090262661804, 'epochs': 87, 'batch_size': 16}. Best is trial 13 with value: 0.22473221371986252.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:48:59,525] Trial 14 finished with value: 0.22876041846469897 and parameters: {'units_l1': 188, 'dropout_l1': 0.20101032956826073, 'units_l2': 67, 'dropout_l2': 0.35431733049490444, 'units_l3': 93, 'lr': 0.005908254076699916, 'epochs': 89, 'batch_size': 32}. Best is trial 14 with value: 0.22876041846469897.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:49:07,217] Trial 15 finished with value: 0.14131351183518015 and parameters: {'units_l1': 204, 'dropout_l1': 0.19454842554977375, 'units_l2': 66, 'dropout_l2': 0.352663537184908, 'units_l3': 92, 'lr': 0.002552236610997908, 'epochs': 88, 'batch_size': 32}. Best is trial 14 with value: 0.22876041846469897.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:49:12,737] Trial 16 finished with value: 0.16036339278906775 and parameters: {'units_l1': 202, 'dropout_l1': 0.20708582963714683, 'units_l2': 90, 'dropout_l2': 0.2714320138054999, 'units_l3': 77, 'lr': 0.0062754674602798766, 'epochs': 86, 'batch_size': 32}. Best is trial 14 with value: 0.22876041846469897.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:49:18,461] Trial 17 finished with value: 0.2139226986817402 and parameters: {'units_l1': 192, 'dropout_l1': 0.24155792164183199, 'units_l2': 93, 'dropout_l2': 0.27594146485667015, 'units_l3': 103, 'lr': 0.007352505599988587, 'epochs': 113, 'batch_size': 32}. Best is trial 14 with value: 0.22876041846469897.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:49:25,927] Trial 18 finished with value: 0.23037839624302714 and parameters: {'units_l1': 288, 'dropout_l1': 0.18091525458384894, 'units_l2': 78, 'dropout_l2': 0.363904426469564, 'units_l3': 86, 'lr': 0.002912111633421934, 'epochs': 97, 'batch_size': 16}. Best is trial 18 with value: 0.23037839624302714.\n",
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-15 11:49:31,592] Trial 19 finished with value: 0.15572802486161075 and parameters: {'units_l1': 279, 'dropout_l1': 0.16577150829804949, 'units_l2': 68, 'dropout_l2': 0.36941886138764285, 'units_l3': 71, 'lr': 0.003154274769852997, 'epochs': 99, 'batch_size': 32}. Best is trial 18 with value: 0.23037839624302714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 7.0307 - mae: 4.3585 - val_loss: 3.5482 - val_mae: 2.4406\n",
      "Epoch 2/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.4433 - mae: 2.5438 - val_loss: 2.3373 - val_mae: 1.8333\n",
      "Epoch 3/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.2031 - mae: 1.7553 - val_loss: 1.9632 - val_mae: 1.6801\n",
      "Epoch 4/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.0561 - mae: 1.8165 - val_loss: 1.8835 - val_mae: 1.7222\n",
      "Epoch 5/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9036 - mae: 1.7523 - val_loss: 1.7074 - val_mae: 1.6270\n",
      "Epoch 6/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8358 - mae: 1.7870 - val_loss: 1.7763 - val_mae: 1.7850\n",
      "Epoch 7/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7566 - mae: 1.7724 - val_loss: 1.8328 - val_mae: 1.8595\n",
      "Epoch 8/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7432 - mae: 1.7956 - val_loss: 1.6133 - val_mae: 1.6853\n",
      "Epoch 9/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5832 - mae: 1.6481 - val_loss: 1.5708 - val_mae: 1.6388\n",
      "Epoch 10/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5496 - mae: 1.6441 - val_loss: 1.5675 - val_mae: 1.6785\n",
      "Epoch 11/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5730 - mae: 1.6939 - val_loss: 1.4839 - val_mae: 1.6151\n",
      "Epoch 12/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6803 - mae: 1.8152 - val_loss: 1.5132 - val_mae: 1.6639\n",
      "Epoch 13/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4398 - mae: 1.5727 - val_loss: 1.4533 - val_mae: 1.6074\n",
      "Epoch 14/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5152 - mae: 1.6525 - val_loss: 1.4930 - val_mae: 1.6715\n",
      "Epoch 15/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4546 - mae: 1.6302 - val_loss: 1.4941 - val_mae: 1.6539\n",
      "Epoch 16/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5061 - mae: 1.6827 - val_loss: 1.4756 - val_mae: 1.6536\n",
      "Epoch 17/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4980 - mae: 1.6669 - val_loss: 1.4491 - val_mae: 1.6421\n",
      "Epoch 18/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4518 - mae: 1.6298 - val_loss: 1.4835 - val_mae: 1.6648\n",
      "Epoch 19/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.4082 - mae: 1.5717 - val_loss: 1.4581 - val_mae: 1.6430\n",
      "Epoch 20/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3997 - mae: 1.5788 - val_loss: 1.5314 - val_mae: 1.7214\n",
      "Epoch 21/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2213 - mae: 1.4037 - val_loss: 1.4361 - val_mae: 1.6409\n",
      "Epoch 22/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2599 - mae: 1.4375 - val_loss: 1.4635 - val_mae: 1.6743\n",
      "Epoch 23/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2941 - mae: 1.4817 - val_loss: 1.4852 - val_mae: 1.6572\n",
      "Epoch 24/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3978 - mae: 1.5685 - val_loss: 1.5054 - val_mae: 1.7026\n",
      "Epoch 25/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2811 - mae: 1.4605 - val_loss: 1.4819 - val_mae: 1.6608\n",
      "Epoch 26/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3131 - mae: 1.4743 - val_loss: 1.4981 - val_mae: 1.7054\n",
      "Epoch 27/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3949 - mae: 1.5719 - val_loss: 1.5424 - val_mae: 1.7200\n",
      "Epoch 28/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2953 - mae: 1.4629 - val_loss: 1.4592 - val_mae: 1.6748\n",
      "Epoch 29/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2696 - mae: 1.4471 - val_loss: 1.5394 - val_mae: 1.7286\n",
      "Epoch 30/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1868 - mae: 1.3433 - val_loss: 1.5072 - val_mae: 1.6726\n",
      "Epoch 31/97\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1991 - mae: 1.3518 - val_loss: 1.5497 - val_mae: 1.7345\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5623 - mae: 1.7695\n",
      "Optimized MLP Test MAE: 1.6408697366714478\n",
      "Optimized MLP Test R² Score: 0.19788699501774376\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_xgb_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate XGBoost model\n",
    "xgb_r2 = r2_score(y_test, y_xgb_pred)\n",
    "xgb_mae = mean_absolute_error(y_test, y_xgb_pred)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, y_xgb_pred))\n",
    "print(f\"XGBoost Test MAE: {xgb_mae}\")\n",
    "print(f\"XGBoost Test RMSE: {xgb_rmse}\")\n",
    "print(f\"XGBoost Test R² Score: {xgb_r2}\")\n",
    "\n",
    "# Define Optuna objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(trial.suggest_int('units_l1', 128, 512), activation='leaky_relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train.shape[1],)),\n",
    "        layers.Dropout(trial.suggest_float('dropout_l1', 0.1, 0.5)),\n",
    "        layers.Dense(trial.suggest_int('units_l2', 64, 256), activation='leaky_relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "        layers.Dropout(trial.suggest_float('dropout_l2', 0.1, 0.5)),\n",
    "        layers.Dense(trial.suggest_int('units_l3', 32, 128), activation='leaky_relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    optimizer = keras.optimizers.AdamW(learning_rate=trial.suggest_float('lr', 5e-4, 1e-2, log=True))\n",
    "    model.compile(optimizer=optimizer, loss=keras.losses.Huber(), metrics=['mae'])\n",
    "    \n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=trial.suggest_int('epochs', 50, 150), batch_size=trial.suggest_categorical('batch_size', [16, 32, 64]), callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Train final model with best hyperparameters\n",
    "best_params = study.best_params\n",
    "final_model = keras.Sequential([\n",
    "    layers.Dense(best_params['units_l1'], activation='leaky_relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(best_params['dropout_l1']),\n",
    "    layers.Dense(best_params['units_l2'], activation='leaky_relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(best_params['dropout_l2']),\n",
    "    layers.Dense(best_params['units_l3'], activation='leaky_relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "final_optimizer = keras.optimizers.AdamW(learning_rate=best_params['lr'])\n",
    "final_model.compile(optimizer=final_optimizer, loss=keras.losses.Huber(), metrics=['mae'])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "final_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=best_params['epochs'], batch_size=best_params['batch_size'], callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Evaluate final model\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "test_loss, test_mae = final_model.evaluate(X_test, y_test)\n",
    "print(f\"Optimized MLP Test MAE: {test_mae}\")\n",
    "print(f\"Optimized MLP Test R² Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Optimized MLP Model Interpretation**\n",
    "**Test MAE: 1.64** → The average absolute error is **1.64 ppb** in the log-transformed DON concentration.  \n",
    "**Test R² Score: 0.198** → The model explains **19.8%** of the variance in DON concentration.  \n",
    "\n",
    "### **What This Means**\n",
    "1. **Slight Improvement**  \n",
    "   - Compared to previous results, the **R² score increased slightly**, indicating that the model is learning **better patterns** in the data.  \n",
    "   - However, a score of **~0.20 R²** still means the model isn't capturing most of the variance.  \n",
    "\n",
    "2. **Possible Issues**\n",
    "   - **PCA (200 components)**: Might still be **removing too much information**.\n",
    "   - **Deep Learning Limitations**: MLP might not be the best choice for this **high-dimensional structured data**.\n",
    "   - **Non-linearity in Data**: XGBoost and stacking might still outperform MLP due to tree-based models handling **complex relationships** better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/TASK-ML-INTERN.csv\")\n",
    "\n",
    "# Log-transform the target variable to reduce skewness\n",
    "df[\"vomitoxin_ppb\"] = np.log1p(df[\"vomitoxin_ppb\"])\n",
    "\n",
    "# Identify and handle outliers using Winsorization\n",
    "Q1 = df[\"vomitoxin_ppb\"].quantile(0.25)\n",
    "Q3 = df[\"vomitoxin_ppb\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "df[\"vomitoxin_ppb\"] = np.clip(df[\"vomitoxin_ppb\"], lower_bound, upper_bound)\n",
    "\n",
    "# Normalize spectral features using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = df.iloc[:, 1:-1].values  # Selecting spectral reflectance features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = df[\"vomitoxin_ppb\"].values  # Transformed target\n",
    "\n",
    "# Apply PCA to retain optimal variance (Increased to 200 components)\n",
    "pca = PCA(n_components=200)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_xgb_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate XGBoost model\n",
    "xgb_r2 = r2_score(y_test, y_xgb_pred)\n",
    "xgb_mae = mean_absolute_error(y_test, y_xgb_pred)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, y_xgb_pred))\n",
    "print(f\"XGBoost Test MAE: {xgb_mae}\")\n",
    "print(f\"XGBoost Test RMSE: {xgb_rmse}\")\n",
    "print(f\"XGBoost Test R² Score: {xgb_r2}\")\n",
    "\n",
    "# Define Optuna objective function for hyperparameter tuning\n",
    "def objective(trial):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(trial.suggest_int('units_l1', 128, 512), activation='leaky_relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train.shape[1],)),\n",
    "        layers.Dropout(trial.suggest_float('dropout_l1', 0.1, 0.5)),\n",
    "        layers.Dense(trial.suggest_int('units_l2', 64, 256), activation='leaky_relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "        layers.Dropout(trial.suggest_float('dropout_l2', 0.1, 0.5)),\n",
    "        layers.Dense(trial.suggest_int('units_l3', 32, 128), activation='leaky_relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    optimizer = keras.optimizers.AdamW(learning_rate=trial.suggest_float('lr', 5e-4, 1e-2, log=True))\n",
    "    model.compile(optimizer=optimizer, loss=keras.losses.Huber(), metrics=['mae'])\n",
    "    \n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=trial.suggest_int('epochs', 50, 150), batch_size=trial.suggest_categorical('batch_size', [16, 32, 64]), callbacks=[early_stopping], verbose=0)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    return r2_score(y_test, y_pred)\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Train final model with best hyperparameters\n",
    "best_params = study.best_params\n",
    "final_mlp_model = keras.Sequential([\n",
    "    layers.Dense(best_params['units_l1'], activation='leaky_relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(best_params['dropout_l1']),\n",
    "    layers.Dense(best_params['units_l2'], activation='leaky_relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(best_params['dropout_l2']),\n",
    "    layers.Dense(best_params['units_l3'], activation='leaky_relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "final_optimizer = keras.optimizers.AdamW(learning_rate=best_params['lr'])\n",
    "final_mlp_model.compile(optimizer=final_optimizer, loss=keras.losses.Huber(), metrics=['mae'])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "final_mlp_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=best_params['epochs'], batch_size=best_params['batch_size'], callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "# Stacking Ensemble (XGBoost + MLP)\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=[('xgb', xgb_model)],\n",
    "    final_estimator=Ridge()\n",
    ")\n",
    "stacking_model.fit(X_train, y_train)\n",
    "y_stack_pred = stacking_model.predict(X_test)\n",
    "stack_r2 = r2_score(y_test, y_stack_pred)\n",
    "stack_mae = mean_absolute_error(y_test, y_stack_pred)\n",
    "stack_rmse = np.sqrt(mean_squared_error(y_test, y_stack_pred))\n",
    "print(f\"Stacking Model Test MAE: {stack_mae}\")\n",
    "print(f\"Stacking Model Test RMSE: {stack_rmse}\")\n",
    "print(f\"Stacking Model Test R² Score: {stack_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "# Define multiple ML models\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42)\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42)\n",
    "adaboost_model = AdaBoostRegressor(n_estimators=200, learning_rate=0.05 ,random_state=42)\n",
    "gbr_model = GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=42)\n",
    "\n",
    "# Train models\n",
    "xgb_model.fit(X_train, y_train)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "gbr_model.fit(X_train, y_train)\n",
    "\n",
    "# Create a Voting Regressor (Boosting Ensemble)\n",
    "voting_model = VotingRegressor(estimators=[('xgb', xgb_model), ('lgb', lgb_model), ('cat', adaboost_model), ('gbr', gbr_model)])\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarath_kumar/ImagoAI/myenv/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Regressor Test MAE: 1.674456453617505\n",
      "Voting Regressor Test RMSE: 2.1753289307744588\n",
      "Voting Regressor Test R² Score: 0.23661635823583316\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Voting Regressor\n",
    "y_voting_pred = voting_model.predict(X_test)\n",
    "voting_r2 = r2_score(y_test, y_voting_pred)\n",
    "voting_mae = mean_absolute_error(y_test, y_voting_pred)\n",
    "voting_rmse = np.sqrt(mean_squared_error(y_test, y_voting_pred))\n",
    "print(f\"Voting Regressor Test MAE: {voting_mae}\")\n",
    "print(f\"Voting Regressor Test RMSE: {voting_rmse}\")\n",
    "print(f\"Voting Regressor Test R² Score: {voting_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Voting Regressor Model Performance Interpretation**\n",
    "✅ **Test MAE: 1.67** → The average absolute error is **1.67 ppb** in log-transformed DON concentration.  \n",
    "✅ **Test RMSE: 2.18** → The model’s root mean squared error is **2.18 ppb**, showing how much it deviates from actual values.  \n",
    "✅ **Test R² Score: 0.237** → The model explains **23.7% of the variance**, which is an **improvement** but still **not ideal**.\n",
    "\n",
    "\n",
    "### **What This Means**\n",
    "1. **Better than MLP (R² ≈ 0.198)**\n",
    "   - The **Voting Regressor (stacking multiple models)** improved the variance explanation.\n",
    "   - However, an R² of **~0.24** is still low, meaning **more than 75% of the variance is unexplained**.\n",
    "\n",
    "2. **Possible Issues**\n",
    "   - **Spectral Features Might Need Different Processing** → PCA (200 components) might **remove useful information**.  \n",
    "   - **Boosting Models Need Further Tuning** → XGBoost, LightGBM, and Adaboost may need **hyperparameter tuning**.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
